```{r setup, include=FALSE}
# Required R package installation:
# These will install packages if they are not already installed
# Set the correct default repository
r = getOption("repos")
r["CRAN"] = "http://cran.rstudio.com"
options(repos = r)


if (!require("knitr")) {
  install.packages("knitr")
  library(knitr)
}

if (!require("kableExtra")) {
  install.packages("kableExtra")
  library(kableExtra)
}

knitr::opts_chunk$set(echo = TRUE)

source("Elasticsearch.R")
```

## Demo for semantic similarity search using Universal Sentence Encoder embeddings and Elasticsearch.

### Configure the search parameters here:

Note: large date ranges can take some time to process on initial search due to the sheer volume of data we have collected. Subsequent searches using the same date range should run quickly due to Elasticsearch caching.

```{r}
# query start date/time (inclusive)
rangestart <- "2020-01-01 00:00:00"

# query end date/time (exclusive)
rangeend <- "2020-08-01 00:00:00"

# text filter restricts results to only those containing words, phrases, or meeting a boolean condition. This query syntax is very flexible and supports a wide variety of filter scenarios:
# words: text_filter <- "cdc nih who"  ...contains "cdc" or "nih" or "who"
# phrase: text_filter <- '"vitamin c"' ...contains exact phrase "vitamin c"
# boolean condition: <- '(cdc nih who) +"vitamin c"' ...contains ("cdc" or "nih" or "who") and exact phrase "vitamin c"
#full specification here: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html
text_filter <- ""

# location filter acts like text filter except applied to the location of the tweet instead of its text body.
location_filter <- ""

# if FALSE, location filter considers both user-povided and geotagged locations. If TRUE, only geotagged locations are considered.
must_have_geo <- FALSE

# query semantic similarity phrase (choose one of these examples or enter your own)
#semantic_phrase <- "Hemoglobin"
#semantic_phrase <- "How do you stay at home when you are homeless?"
#semantic_phrase <- "My wedding has been postponed due to the coronavirus."
#semantic_phrase <- "I lost my job because of COVID-19. How am I going to be able to make rent?"
#semantic_phrase <- "I am diabetic and out of work because of coronavirus. I am worried I won't be able to get insulin without insurance."
#semantic_phrase <- "There is going to be a COVID-19 baby boom..."
#semantic_phrase <- "colleges and universities"
semantic_phrase <- "i hate masks"

# number of results to return (max 10,000)
resultsize <- 1000
# minimum number of results to return. This should be set according to the needs of the analysis (i.e. enough samples for statistical significance)
min_results <- 1
```

### Results:

```{r, echo=FALSE}
results <- do_search(indexname="coronavirus-data-masks", 
                     rangestart=rangestart,
                     rangeend=rangeend,
                     text_filter=text_filter,
                     location_filter=location_filter,
                     semantic_phrase=semantic_phrase,
                     must_have_embedding=TRUE,
                     must_have_geo=must_have_geo,
                     resultsize=resultsize,
                     resultfields='"created_at", "user.screen_name", "text", "full_text", "extended_tweet.full_text"',
                     elasticsearch_host="",
                     elasticsearch_path="elasticsearch",
                     elasticsearch_port=443,
                     elasticsearch_schema="https")

required_fields <- c("cosine_similarity", "full_text", "created_at", "user_screen_name")
validate_results(results$df, min_results, required_fields)

#print results
params.df <- data.frame(from=results$params$rangestart, 
                        to=results$params$rangeend,
                        text.filter=results$params$text_filter,
                        location.filter=results$params$location_filter,
                        phrase=results$params$semantic_phrase,
                        geo_only=results$params$must_have_geo,
                        results.count=paste(nrow(results$df), "/", results$total))
kable(params.df) %>% kable_styling()

display.df <- results$df[, required_fields]
kable(display.df) %>% kable_styling()
```